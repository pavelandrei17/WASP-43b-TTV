{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4e20d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylightcurve as plc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from scipy import stats\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de2499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jd,raw_flux, raw_flux_err = np.loadtxt('Photometry_results.csv', delimiter=',', skiprows=1, usecols = [1,2,3], unpack=True)\n",
    "jd,raw_flux, raw_flux_err = np.loadtxt('All_photometry.csv', delimiter=',', skiprows=1, usecols = [0,1,2], unpack=True)\n",
    "std_fluxes = np.loadtxt('All_photometry.csv', delimiter=',', skiprows=1, usecols = [3,5,7,9,11,13,15,17,19,21,23,25], unpack=True)\n",
    "std_fluxes_err = np.loadtxt('All_photometry.csv', delimiter = ',', skiprows=1, usecols = [4,6,8,10,12,14,16,18,20,22,24,26], unpack=True)\n",
    "\n",
    "std_flux = np.sum(std_fluxes,axis=0)\n",
    "std_flux_err = np.sqrt(np.sum(std_fluxes_err**2, axis=0))#std_flux1_err**2+std_flux2_err**2+std_flux3_err**2+std_flux4_err**2+std_flux5_err**2)\n",
    "flux = raw_flux/std_flux\n",
    "flux_err = flux*np.sqrt((raw_flux_err/raw_flux)**2+(std_flux_err/std_flux)**2)\n",
    "\n",
    "flux_unc_std = np.std(flux[-18:]) #Uncertainty empirically found from the std of photos post-transit end\n",
    "star_flux = flux[-18:]\n",
    "jd_star = jd[-18:]\n",
    "star_flux_avg = np.average(star_flux)\n",
    "star_flux_avg_err = np.std(star_flux)/np.sqrt(18) #Standard Error of the Mean \n",
    "normalised_flux = flux/star_flux_avg\n",
    "normalised_err = normalised_flux*np.sqrt((flux_err/flux)**2 + (star_flux_avg_err/star_flux_avg)**2)\n",
    "normalised_std = flux_unc_std/star_flux_avg\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bece0e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(jd, raw_flux, '.')\n",
    "plt.xlabel(\"Time (JD)\")\n",
    "plt.ylabel(\"Flux (ADUs)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('raw_lightcurve.jpg')\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.errorbar(jd, normalised_flux, yerr=normalised_err, fmt='.', capsize=3)\n",
    "plt.xlabel(\"Time (JD)\")\n",
    "plt.ylabel(\"Relative flux\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('detrended_lightcurve2.jpg')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62b88ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binning(time_adj, flux, flux_err,  n, expo=45):\n",
    "    if type(flux_err) == np.float64:\n",
    "        flux_err = np.asarray([flux_err] * len(flux))\n",
    "    start_binning = time.process_time()\n",
    "    print('Number of points:', len(flux))\n",
    "    number = time_adj.size\n",
    "    #We want to have n observations. Hence, each bin will include a 1/n of all observations\n",
    "    bin_width_float = number/n\n",
    "    bin_width = int(bin_width_float)\n",
    "    i=0\n",
    "    bin_start_arr = np.array([])\n",
    "    bin_mid_arr = np.array([])\n",
    "    binned_flux = np.array([])\n",
    "    time_width_arr = np.array([])\n",
    "    binned_flux_err = np.array([])\n",
    "    int_time = np.array([])\n",
    "    while i<=(n-1):  \n",
    "        if i == 0:\n",
    "            start = 0\n",
    "        else:\n",
    "            start = i*bin_width \n",
    "        if i == n-1:\n",
    "            end = time_adj.size\n",
    "        else:\n",
    "            end = (i+1)*bin_width\n",
    "        #print('Bin from number {0} to number {1}'.format(start,end))\n",
    "        time_group = time_adj[start:end]\n",
    "        time_width = time_group.max()-time_group.min()\n",
    "        time_width_arr = np.append(time_width_arr, time_width)\n",
    "        flux_group = flux[start:end]\n",
    "        flux_err_group = flux_err[start:end]\n",
    "        time_avg = np.average(time_group)\n",
    "        flux_avg= np.average(flux_group)\n",
    "        term_flux_bin_err = np.sqrt(np.sum(flux_err_group**2)/len(flux_err_group))\n",
    "        flux_bin_err= term_flux_bin_err/np.sqrt(len(flux_group))\n",
    "        #flux_bin_err= np.median(flux_err)/np.sqrt(len(flux_group))\n",
    "        bin_start = time_group[0]\n",
    "        bin_end = time_group[-1] + expo/86400\n",
    "        bin_start_arr = np.append(bin_start_arr, bin_start)\n",
    "        bin_mid_arr = np.append(bin_mid_arr, (bin_end+bin_start)/2)\n",
    "        binned_flux = np.append(binned_flux, flux_avg)\n",
    "        binned_flux_err = np.append(binned_flux_err, flux_bin_err)\n",
    "        int_time = np.append(int_time, expo*len(flux_group))\n",
    "        if i ==0:\n",
    "            processed_tot = time_group.size\n",
    "        else:\n",
    "            processed_tot = processed_tot + time_group.size\n",
    "        i +=1 \n",
    "    int_time_avg =  stats.mode(int_time)[0][0] \n",
    "    print('Integration times:', int_time)\n",
    "    print('All {0} bins have been created with total integration time {1} s, each spanning on average {2} s.'\\\n",
    "          .format(i, int_time_avg, 86400*np.median(time_width_arr)))\n",
    "    save_bins =np.array([bin_start_arr, bin_mid_arr, binned_flux, binned_flux_err, int_time])\n",
    "    return save_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d157a1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_wasp43 = binning(jd, normalised_flux, normalised_err, 21)\n",
    "plt.figure()\n",
    "plt.errorbar(bins_wasp43[1], bins_wasp43[2], yerr=bins_wasp43[3], fmt='.', capsize=3)\n",
    "plt.xlabel('Time (JD)')\n",
    "plt.ylabel('Relative flux')\n",
    "plt.tight_layout()\n",
    "plt.savefig('binned.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fe7c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(binned_obs, mag =12.305):\n",
    "    planet = plc.get_planet('wasp43b')\n",
    "    start_time, mid_time, flux, flux_unc, int_time = binned_obs\n",
    "    planet.add_observation(\n",
    "        time = mid_time,                # the time vector of our observation\n",
    "                                    # np.array of float values \n",
    "\n",
    "        time_format = 'JD_UTC',    # format in which our time vector is expressed\n",
    "                                    # str, available formats are: JD_UTC, MJD_UTC, HJD_UTC, HJD_TDB, BJD_UTC, BJD_TDB \n",
    "\n",
    "        exp_time = stats.mode(int_time)[0][0],             # exposure time of our time vector\n",
    "                                    # float, in seconds\n",
    "\n",
    "        time_stamp = 'mid',         # exposure time stamp for our time vector (do the numbers refer to the exposure start, the mid-exposure, or the exposure end?)\n",
    "                                    # str, available stamps are: start, mid, end \n",
    "\n",
    "        flux = flux,                # the flux vector of our observation\n",
    "                                    # np.array of float values, \n",
    "\n",
    "        flux_unc = flux_unc,        # the flux-uncertainty vector of our observation\n",
    "                                    # np.array of float values, \n",
    "\n",
    "        flux_format = 'flux',       # format in which our flux and flux-uncertainty vectors are expressed\n",
    "                                    # str, available formats are: flux, mag\n",
    "\n",
    "        filter_name = 'luminance'   # filter used for this observation \n",
    "                                    # str, available filters are: all the default filters and those added manually by us\n",
    "    )\n",
    "    foldername = 'WASP43-08-03-22_TRY2'\n",
    "    planet.transit_fitting(foldername)\n",
    "    t_uncertainty = np.average(np.abs(np.loadtxt('./{0}/results.txt'.format(foldername), skiprows=14, usecols = [2,3])))\n",
    "    return  t_uncertainty"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
